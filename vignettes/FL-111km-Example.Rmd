---
title: "Runthrough"
params: 
 plot: TRUE 
 table: TRUE
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Runthrough}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  message = TRUE, 
  echo=FALSE, 
  warning=FALSE
)
rm(list=ls())
```

```{r load-pkg}
## Users may run into issues when installing the following packages
devtools::install_github("ropensci/rnaturalearth", force=FALSE) ## must install from GH -- source has unresolved issues for 2+years (see issue https://github.com/ropensci/rnaturalearthhires/issues/1)

unloadNamespace("dubcorms") # just a precaution to ensure we get most recent dev version of pkg
devtools::install_github("trashbirdecology/dubcorms", force=FALSE)
library(dubcorms)
library(dplyr) # we use a LOT of functions from here and often so just load the entire thing
library(sf) # we use a LOT of functions from here and often so just load the entire thing
```
# Step 1: Setup and Specifications
## Specs for data subsetting
First, specify the species, regions, and time frames where necessary. 
```{r specs-subsetting}
## List out the various uses of the species names and abbreviations, just to be safe. 
interest.species <- c("DOCCOR", "DOCCO", "DCCO", "DCCOR", "Double-crested Cormorant", "Double Crested Cormorant") 

## List the countries of interest
countries <- c("Canada","USA", "United States", "United States of America") # used to create base maps

## Specify the regions you know you definitely don't want to use.
region.remove = c("Alaska", "Hawaii", "Northwest Territories", "Yukon", "Nunavut", "Yukon Territory") 

## Specify the states/provinces of interest.
states <- c("FL", "US-FL", "Florida")

## Time frames
### range of years for subsetting observations
year.range <- c(2008:lubridate::year(Sys.Date()))
### range of days of the year for subsetting ebird and bbs data 
min.yday <- 91  # approximate breeding season day start (day of year)
max.yday <- 245 # approximate breeding season day end (day of year)
```

```{r specs-directories}
## Create a shorthand name for the project
proj.shorthand="fl"
```

## BBS Data Specifications
The following specifications are for munging BBS data
```{r specs-bbs}
include.unid <- FALSE ## Whether or not to include UNIDENTIFIED // hybrid species
```

## eBird Data Specifications
The following specifications are for munging eBird data
```{r specs-ebird}
ebird.protocol <- c("Traveling", "Stationary")
complete.checklists.only <- TRUE
max.effort.mins <-  3*60 ## arbitrary
max.effort.km   <-  5 #This is coarse also, typically 5km or less
max.num.observers <- 10
mmyyyy <- "Oct-2021" # month and year of most recent ebird EBD/samp download in file.
```


## Geospatial specifications
```{r specs-geospatial}
## specify the target geographic or projected coordinate reference system (CRS)
crs.target <- 4326 # 4326 == unprojected; 5070=Alberts equal area (used by USGS)

## provide the desired grid cell size (units== decimal degrees)
### A good estimate for large-scale (>=state) studies in North Am.
#### is that there are 111.111km in 1 degree latitude or longitude
#### miles to km: km=1.61*miles
grid.size=1.00 #== 1 dec deg
```

## Directory specifications and naming
```{r specs-dir-touch}
## Where is your original eBird data stored?
dir.ebird.in <- "C:/Users/jburnett/OneDrive - DOI/research/cormorants/dubcorm-data-backup/ebird"
## Where are the BBS route shapefiles stored?
cws.routes.dir <- "C:/Users/jburnett/OneDrive - DOI/research/cormorants/dubcorm-data-backup/bbs/route_shapefiles/cws"
usgs.routes.dir <- "C:/Users/jburnett/OneDrive - DOI/research/cormorants/dubcorm-data-backup/bbs/route_shapefiles/usgs"
```

```{r specs-dir-donottouch}
## automatically creates a new directory for storing munged data, results, figures, etc. based on project shorthand name. 
dir.proj.out <- paste0(proj.shorthand,"-example-", round(grid.size*111.111), "km/")
## where to store the JAGS objects
dir.jags <- paste0(dir.proj.out, "jags/")
dir.bbs.out <- paste0(dir.proj.out,"bbs/")
dir.ebird.out <- paste0(dir.proj.out,"ebird/")
dir.spatial.out <- paste0(dir.proj.out,"spatial/")
dir.plots <- paste0(dir.proj.out, "plots/")
sapply(c(dir.proj.out, dir.bbs.out, dir.ebird.out, dir.spatial.out, dir.jags, dir.plots), FUN=
         function(x) dir.create(x, showWarnings = FALSE))
```

## Set Chunk Evaluation Conditions
```{r set-eval-conditions, include=FALSE}
## establish conditions for skipping data munging chunks if data already exists for this example!
 eval_bbs <- dplyr::if_else("bbs.rds" %in% list.files(dir.jags), FALSE, TRUE)
 eval_ebird <- dplyr::if_else("ebird.rds" %in% list.files(dir.jags), FALSE, TRUE)
 eval_grid <- dplyr::if_else("grid.rds" %in% list.files(dir.jags), FALSE, TRUE)
 eval_combo <- if_else(!eval_bbs & !eval_ebird & !eval_grid, FALSE, TRUE)
```

```{r specify-junk, eval=TRUE}
# save a list of elements we always want to keep in memory
# we also distinguish between the base argumensts for use later in making metadata tables describving our jags objects. 
args.save <- args.save.base <- c("args.save.base", ls()) 
```

# Step 2: Make a Spatial Grid
If the spatial grid R object, `grid.rds`, already exists in `r dir.proj.out`, load it into file. If not, will create a new spatial grid and save to file. 
```{r make-grid, eval=eval_grid}
## If a grid.rds is saved in project directory, will not run script and instead will load that file into memory
## load in that rds.
if("grid.rds" %in% list.files(dir.spatial.out)) grid <- readRDS(paste0(dir.spatial.out, "/", "grid.rds"))else{
study.area <-
  rnaturalearth::ne_states(country = countries, returnclass = "sf") %>%
  # remove region(s)
  filter(tolower(name) %in% tolower(states)) %>%
  filter(!tolower(name) %in% tolower(region.remove)) %>%
  sf::st_transform(study.area, crs = crs.target)
# unique(study.area$adm0_a3) #should add a test here to make sure number of countries expected is grabbed.

# throw a grid over the study area layer
grid <- study.area %>%
  sf::st_make_grid(cellsize = grid.size,
               square = FALSE,
               flat_topped = TRUE) %>%
  sf::st_intersection(study.area) %>%
  # st_cast("MULTIPOLYGON") %>%
  sf::st_sf() %>%
  mutate(gridcellid = row_number()) %>%
  sf::st_transform(crs = crs.target)

# # Visualize to check
# tmap::qtm(grid)
# mapview::mapview(grid) # interactive, openstreetmap

# Add centroid lat lon to grid 
centroid.coords <- sf::st_coordinates(sf::st_geometry(sf::st_centroid(grid)))
grid$cell.lon.centroid <- centroid.coords[,1]
grid$cell.lat.centroid <- centroid.coords[,2]

# Export Data
saveRDS(grid, file = paste0(dir.spatial.out, "/", "grid.rds"))
}
# Clear junk
args.save <- junk_it(args.save, "grid")
```

# Step 3: Load or Create BBS and eBird Data
## Step 3a: Check to see if the munged spatial data files already exist.
If these files already exist, this will load in those files and skip steps 3b and 3c.
```{r spatial-files-load, include=FALSE, eval=eval_combo}
## If all files do not exist, then something is may have gone awry in a previous session and we should be safe and re-create everything.
fns.spatial <- c("bbs_spatial.rds", "ebird_spatial.rds", "grid.rds")
if(all(fns.spatial %in% list.files(dir.spatial.out))){
  cat("importing bbs, ebird and grid sf objects.")
  fns.spatial <-list.files(dir.spatial.out, full.names = TRUE)
  bbs_spatial <- readRDS(fns.spatial[stringr::str_detect(fns.spatial, "bbs_spat")])
  grid <- readRDS(fns.spatial[stringr::str_detect(fns.spatial, "grid")])
  ebird_spatial <- readRDS(fns.spatial[stringr::str_detect(fns.spatial, "ebird_spat")])
  ## If you want to check out the spatial grid wtih some basic BBS stats, go for it:
  browseURL(list.files(dir.plots, "bbs_spatial_exploratory.pdf", full.names=TRUE))# opens the PDF!
  }
```

## Step 3b: BBS Data Munging
Depending on the size of the study area, resolution of the grid cells, and whether you've already downloaded the BBS data, this may take a few minutes.
```{r bbs-munge, eval=eval_bbs}
# Do not run if bbs_spatial already exists
if(!exists("bbs_spatial")){
# Check for existing files ------------------------------------------------
fns <- list.files(dir.bbs.out)
fns.spatial <- list.files(dir.spatial.out)
if("bbs_spatial.rds" %in% tolower(fns.spatial)) bbs_spatial <- readRDS(paste0(dir.spatial.out, "/", "bbs_spatial.rds"))else{

# Munge BBS data ----------------------------------------------------------
## Import and/or Download BBS Observations and Metadata -----------------------------
#### Original observations data
if("bbs_orig.rds" %in% tolower(fns)){
  bbs_orig <-
    readRDS(paste0(dir.bbs.out, "/bbs_orig.rds"))} else{
      print("grabbing bbs data, this might take 45sec")
      bbs_orig <- grab_bbs_data(sb_dir = dir.bbs.out)
      saveRDS(bbs_orig, paste0(dir.bbs.out, "/bbs_orig.rds"))
}

#### Munged observations data
if (!"bbs_obs.rds" %in% tolower(fns)) {
  bbs_obs <-
    munge_bbs(
      list = bbs_orig,
      spp = interest.species,
      states=states,
      keep.stop.level.data = FALSE
    )
  saveRDS(bbs_obs, paste0(dir.bbs.out, "/bbs_obs.rds"))
} else{
  bbs_obs <- readRDS(paste0(dir.bbs.out, "/bbs_obs.rds"))
}

## Make BBS Spatial Layers ----------------------------------------------
### Create BBS routes spatial layer ----------------------------------------------------------------------
# munges all routes at first then moves to subsetting to the grid, so have patience
# takes about a minute for 1-3 states
cat("Munging the BBS route shapefiles/spatial layer.\nIf `grid` specified, will take a hot minute.\n\n")
bbs_spatial <-
  make_bbs_spatial(
    bbs.obs = bbs_obs,
    cws.routes.dir = cws.routes.dir, #location of the CWS BBS routes shapefiles
    usgs.routes.dir = usgs.routes.dir, #location of the USGS BBS routes shapefiles
    crs.target = crs.target,
    routes.keep=unique(bbs_obs$RTENO),
    grid=grid,
    keep.empty.cells =TRUE,
    plot.dir=dir.plots,
    overwrite=TRUE
  )

saveRDS(bbs_spatial, paste0(dir.spatial.out, "/bbs_spatial.rds"))
## View the file with basic bbs stats against the spatial grid
browseURL(list.files(dir.plots, "bbs_spatial_exploratory", full.names = TRUE))
}

args.save <- junk_it(args.save, "bbs_spatial")
}
```

## Step 3c: eBird Data Munging 
Due to the size of the eBird data, it may take many many minutes to munge the data. 
```{r ebird-data, eval=eval_ebird}
# Do not run if bbs_spatial already exists
if(!exists("ebird_spatial")){
if (parallel::detectCores() <= 4 |
    memory.limit() < 25000)
  warning(
    "You probably don't have enough RAM and/or CPU to munge the eBird data. Don't blame me if your machine crashes. If `filter_ebird_data` takes longer than 20 minutes, something is probably wrong.\n\n"
  )

fns.ebird <- id_ebird_files(dir.ebird.in = dir.ebird.in)

# Filter the eBird Data ---------------------------------------------------
ebird_filtered <- filter_ebird_data(
                                    fns.ebird = fns.ebird,
                                    overwrite = FALSE,
                                    dir.ebird.out = dir.ebird.out,
                                    countries = countries,
                                    states = states,
                                    protocol = c("Traveling","Stationary"),
                                    species = interest.species,
                                    max.num.observers=max.num.observers,
                                    years=year.range
                                    )

## Zero-fill the eBird Data -------------------------------------------------
fns <- list.files(dir.ebird.out, full.names = TRUE, pattern = "filtered.txt")

# would like to get this functional but auk_zerofill currently requires
## VERY specific coltypes and names. not flexible in coltypes...
# ebird_zf <- auk::auk_zerofill(x=fns[fns %>% stringr::str_detect("obs")],
#                               sampling_events = fns[fns %>% stringr::str_detect("samp")])

ebird_zf <- zerofill_ebird(myList=ebird_filtered, overwrite=FALSE, dir.out=dir.ebird.out)

## Create the eBird Spatial Layer  -----------------------------------------------------
### need to add argument in make_ebird_spatial function to load in file if it exists...
### maybe also save to file inside that funciton 
ebird_spatial <- make_ebird_spatial(df=ebird_zf, crs.target = crs.target)

## Export eBird Spatial Data -------------------------------------------------------------
saveRDS(ebird_spatial, file = paste0(dir.spatial.out, "ebird_spatial.rds"))
# list.files(dir.spatial.out, "spatial.rds")
# remove junk ----------------------------------------------------------------------------
args.save <- junk_it(args.save, "ebird_spatial")

}
```

## Step 3d: Basic Tests
Just double-check the CRS on the spatial files. They all should be the same before we integrate. 
```{r test-crs, eval=eval_grid}
if(!(sf::st_crs(grid)==sf::st_crs(bbs_spatial) & sf::st_crs(ebird_spatial)==sf::st_crs(grid)))stop("Warning. The ebird, bbs, and grid spatial layers are not in same projection and/or CRS.")

if(!all(grid$gridcellid %in% unique(c(ebird_spatial$gridcellid, bbs_spatial$gridcellid))))
  warning("Empty grid cells (no ebird or bbs data) are not represented in the bird data.\nShould make sure empty cells are added to bird data.")
```

# Step 4: Integrate the BBS and eBird Spatial Data
To ensure proper integration (or rather, use of all data in JAGS) we need to munge the ebird and bbs spatial data just a little bit. We first ensure column names map to eachtoher, where appropriate (e.g., bird count, dates).
```{r match-colnames, eval=eval_combo}
## Force BBS colnames to lowercase.
names(bbs_spatial) <- tolower(names(bbs_spatial))
bbs_spatial <- match_col_names(bbs_spatial)
ebird_spatial <- match_col_names(ebird_spatial)
```

Next, munge the dates, times, julian dates, and days of year for each dataset such that we can properly align on the temporal dimension.
```{r munge-dates-times, eval=eval_combo}
# Handle Dates and Times --------------------------------------------------
cat("managing dates and times of spatial objects")
# Dates ---------------------------------------------
## make julian dates
bbs_spatial$date <- lubridate::as_date(bbs_spatial$date)
ebird_spatial$date <- lubridate::as_date(ebird_spatial$date)
## base date for julian date
#### eventually will need to save this or export it somewhere, maybe add it to jags list idk
base.date <- min(c(bbs_spatial$date, ebird_spatial$date), na.rm=TRUE)
## make julian dates
bbs_spatial$julian <- julian(bbs_spatial$date, origin = base.date)
ebird_spatial$julian <- julian(as.Date(ebird_spatial$date), origin = base.date)
## make day of year
ebird_spatial$yday <- lubridate::yday(ebird_spatial$date)
bbs_spatial$yday <- lubridate::yday(bbs_spatial$date)

## Filter days of the year if specified
if(exists("yday")) ebird_spatial <- ebird_spatial %>%
  filter(yday >= min.yday & yday <= max.yday)
if(exists("yday")) ebird_spatial <- ebird_spatial %>%
  filter(yday >= min.yday & yday <= max.yday)

# Times ---------------------------------------------
### this is an ugly workaround and can be improved, including putting it into
### the BBS and eBird munging functions but this is it for now.
bbs_spatial$starttime=hms::as_hms(as.POSIXct(bbs_spatial$starttime, format="%H%M"))
bbs_spatial$endtime=hms::as_hms(as.POSIXct(bbs_spatial$endtime, format="%H%M"))
ebird_spatial$time_observations_started=hms::as_hms(as.POSIXct(ebird_spatial$time_observations_started, format="%H:%M:%S"))
```

If you don't need local sunlight/rise/set times, specify `eval=FALSE` in this chunk. This process takes a while and sometimes crashes when computing on the ebird data. 
```{r munge-sunlight, eval=eval_combo}
# Sunlight/daylight/moonlight ---------------------------------------------
## here, data must have columns lat and lon. I took care of this in
## utils.R function `match_col_names()`
cat("calculating astronomical stats...yes, the astronomy definition.\n")
sunlight.keep <- c("dawn", "solarNoon", "sunrise","sunriseEnd")

bbs.sunlight <- suncalc::getSunlightTimes(data=bbs_spatial %>% distinct(date, lon, lat),
                                            keep = sunlight.keep)


## ebird is so large that I need to split up b/c takes forever.
## i'd like to use kit::funique, but cannot figure out how to do that with >1 columns.
### so, am resorting to this method.
x <- ebird_spatial %>% dplyr::select(date, lat, lon)
chunks <- parallel::splitIndices(nrow(x), 100)
for(i in seq_along(chunks)){
  if(i==1) ebird.sunlight <- NULL
  rows = as.data.frame(chunks[i])
  chunk.start = min(rows[1])
  chunk.end   = max(rows[1])
  dat = x[chunk.start:chunk.end, ]
  dat = suncalc::getSunlightTimes(data=dat,
                            keep = sunlight.keep)

  ebird.sunlight <- dplyr::bind_rows(ebird.sunlight,dat)
  rm(dat, chunk.end, chunk.start, rows)
}

### turn vars in sunlight.keep into time only (otherwise they are in YYYY-MM-DD HH-MM-SS; we need only HH-MM)
ebird.sunlight <- ebird.sunlight  %>%
  dplyr::mutate(across(sunlight.keep, hms::as_hms))
bbs.sunlight <- bbs.sunlight %>%
  dplyr::mutate(across(sunlight.keep, hms::as_hms))

### add sunlight information to spatial data
bbs <- left_join(bbs_spatial, bbs.sunlight)
ebird <- left_join(ebird_spatial, ebird.sunlight)
```
Export all these data to a folder for quick use in JAGS data munging activities.
```{r export-munged-data, eval=eval_combo}
saveRDS(bbs, file=paste0(dir.jags, "bbs.rds"))
saveRDS(ebird, file=paste0(dir.jags, "ebird.rds"))
saveRDS(grid, file=paste0(dir.jags, "grid.rds"))
args.save <- junk_it(args.save, c("bbs","grid","ebird"))
```

# Step 5: Create Data for Use in JAGS
Import the munged bbs, ebird and grid sf objects
```{r import-spatial-bird-data, eval=TRUE}
# Create or Load in Post-spatial Munging BBS and eBird Data
fns <- list.files(dir.jags, full.names = TRUE)
if(!eval_bbs)   bbs <- readRDS(fns[stringr::str_detect(fns, "bbs.rds")])
if(!eval_grid)  grid <- readRDS(fns[stringr::str_detect(fns, "grid.rds")])
if(!eval_ebird) while(!exists("ebird")) ebird <- readRDS(fns[stringr::str_detect(fns, "ebird.rds")])
args.save <- junk_it(args.save, c("bbs","grid","ebird"))
```

Although the data are ready for use and technically integratable, we need to munge the data just a little further.

## Grid/Study Area
Create some indicators describing the grid for use in JAGS.
```{r prep-grid-jags}
library(sf)
library(dplyr)
library(reshape2)
## create a data frame for indexing off the grid cell
grid.df <- grid %>%
  arrange(gridcellid) %>%
  st_drop_geometry()

### create an index for the grid cells with count data
gridcellswbbs <- unique(bbs$gridcellid) %>% sort()
gridcellswebird <- unique(ebird$gridcellid) %>% sort()
gridcellswdata <- unique(c(gridcellswbbs, gridcellswebird))

## grid cell centroid coordinates
XY <- grid.df %>% # centroid coordinates of the grid cells
  select(cell.lon.centroid, cell.lat.centroid) %>% as.matrix()
```


Wrap grid data up into a nice little JAGS list
```{r make-grid-jdat}
### create a list of elements relevant to the study area/grid cells
jdat.grid <- list(
  coords.gridcells = XY,
  G = nrow(XY), # integer, number of cells in study area (with or without data)
  id.gridcells = sort(grid.df$gridcellid), # identifier for grid cells
  n.gridcellswdata = length(gridcellswdata), # number of grid cells with any count data (ebird or bbs)
  id.gridcellswdata = sort(gridcellswdata),  # vector of grid cell ids with any count data
  n.gridcellswbbs = length(gridcellswbbs), # number of grid cells with any count data (ebird or bbs)
  id.gridcellswbbs = sort(gridcellswbbs),  # vector of grid cell ids with any count data
  n.gridcellswebird = length(gridcellswebird), # number of grid cells with any count data (ebird or bbs)
  id.gridcellswebird = sort(gridcellswebird)  # vector of grid cell ids with any count data
  )
args.save <- junk_it(args.save, "jdat.grid")
```


## BBS Data

```{r prep-bbs-jags-p-arrays}
require(reshape2)
## scale/mean of stop-level detection covariates
bbs.df <- bbs %>% st_drop_geometry() %>%
  as.data.frame() %>%
  group_by(rteno, year) %>%
  mutate(avgwind = abs(startwind-endwind)/2) %>%
  ungroup() %>% 
  ### remove empty grid cells..
  distinct(rteno, gridcellid, year, C, .keep_all=TRUE) %>%
  filter(!is.na(rteno)) %>%
  ### scale covariates
  mutate(
    wind.z = (avgwind - mean(avgwind, na.rm=TRUE))/sd(avgwind, na.rm=TRUE),
    noise.z = (noisemean - mean(noisemean, na.rm=TRUE))/sd(noisemean, na.rm=TRUE),
    car.z = (carmean - mean(carmean, na.rm=TRUE))/sd(carmean, na.rm=TRUE)
  ) %>%
  ### weighted counts by prop route in cell and cell area
  mutate(C.weighted.area = as.numeric(C*proprouteincell/cellarea)) # weighted C per grid area (# per m^2)

### make route-level observation covariate arrays (dims: rteno by year)
p.cars <-  acast(bbs.df %>% distinct(rteno, year, car.z), rteno~year)
p.noise <-  acast(bbs.df %>% distinct(rteno, year, noise.z), rteno~year)
p.obsfyrbbs <-  acast(bbs.df %>% distinct(rteno, year, obsfirstyearbbs), rteno~year)
p.obsfyrrteno <-  acast(bbs.df %>% distinct(rteno, year, obsfirstyearroute), rteno~year)
p.wind <-  acast(bbs.df %>% distinct(rteno, year, wind.z), rteno~year)

## arrays for trend effects
doy.bbs <-  acast(bbs.df %>% distinct(rteno, year, yday), rteno~year)
```
Create some 
```{r prep-bbs-jags-indexing}
### unique rtenos sampled
id.routessampled <- unique(bbs.df$rteno) %>% sort()
### number of unique routes sampled across the entire dataset
n.routessampled  <- length(id.routessampled)
### number of RTENO sampled each year
n.routesperyear <- bbs.df %>% group_by(year) %>%
  summarise(n = n_distinct(rteno)) %>% arrange(year) %>% ungroup() 
n.routesperyear <- n.routesperyear$n


```

Count data---arrays for BBS count data (dims: rteno by year by grid cell)
```{r prep-bbs-jags-count-arrays}
### C: array <rteno by year by cell id>
C            <-   reshape2::acast(bbs.df, rteno~year~gridcellid, value.var="C")
### C.route: C at the route level
C.route      <-   reshape2::acast(bbs.df %>% distinct(rteno, year, C), rteno~year, value.var="C")

```

Create array for area offsets and weights on the count data. 
```{r prep-bbs-jags-area-offsets}
### w.prop: array containing weights for count data (dims: rteno by grid cell)
w.prop <-
  acast(
    bbs.df %>% distinct(rteno, gridcellid, proprouteincell),
    rteno ~ gridcellid,
    value.var = "proprouteincell"
  ) # % of rteno in a cell

## w.area: an area offset; vector containing area (m^2) for each grid id (dims: grid cell by 1)
w.area <- scale(as.vector(reshape2::acast(bbs.df %>% distinct(gridcellid, cellarea), gridcellid~., value.var="cellarea"))) # area (units in original df) of gri cell.
```

Create indicators for use in JAGS loops
```{r prep-bbs-jags-loop-inds}
R = dim(C)[1] # <route> number of unique BBS routes with data
T.bbs = dim(C)[2] # <time> number of years of BBS data
G.bbs = dim(C)[3] # <site/grid cell> number of unique grid cells sampled by BBS data
```

Specify what to throw into the JAGS list
```{r specify-vars-bbs-jdat}
names.bbs <-
  c(
    "R.bbs", # number of unique routes across entire dataset
    # "G",
    # "T",
    "T.bbs", # will likely always equal T, but just in case
    "G.bbs",
    "C",
    "C.route",
    "id.routessampled",
    "n.routessampled",
    "n.routesperyear",
    "w.area",
    "w.prop",
    "p.obsfyrbbs",
    "p.obsfyrrteno",
    "p.cars",
    "p.noise",
    "p.wind",
    "doy.bbs"
  )
jdat.bbs <- list()
```

Finally, wrap it all up into a nice little JAGS list.
```{r make-bbs-jdat}
for(i in seq_along(names.bbs)){
  jdat.bbs[[i]] <- eval(parse(text=paste(names.bbs[i])))
  names(jdat.bbs)[[i]] <- names.bbs[i] # doing this inside loop to prevent issues where data DNE
}
```

## eBird Data
```{r}


```


Wrap eBird data up into a nice little JAGS list
```{r make-ebird-jdat}
jdat.ebird <- NULL
```


## Integrated JAGS Data Object

```{r write-jdat}
jdat <- c(jdat.bbs, jdat.ebird, jdat.grid)
saveRDS(jdat, file=paste0(dir.jags, "jdat.rds"))

```