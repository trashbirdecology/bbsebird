---
title: "Munge eBird and BBS Data for Integrated Model"
params: 
  proj.shorthand: "fl-ga-example" # this should be same as wht's in 1_Data-munging.Rmd
  dir.orig.data: "C:/Users/jburnett/OneDrive - DOI/research/cormorants/dubcorm-data-backup/" # this should be same as wht's in 1_Data-munging.Rmd
  overwrite.jdat: TRUE
  fn.munging: "1_Data-munging.Rmd" # the first data munging script name
---

Use this script to create data for use in JAGS modelling activities. 

# Step 1: Setup 
 This chunk sources some redundant chunks in the data-munging r markdown
```{r setup}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  message = TRUE, 
  echo=FALSE, 
  warning=FALSE, 
  fig.path="/plots/", 
  tidy=TRUE, 
  include=FALSE
)
# rm(list=ls())# for dev
if(is.null(params$fn.munging)) stop("RMD parameter `params$fn.munging` MUST be specified in YAML header.")
chunk_labels <- c( # please don't change chunk call order
  # "setup",
  "libraries", 
  "specs-subsetting",
  "specs-bbs",
  "specs-ebird",
  "specs-geospatial",
  "specs-dirs",
  "specify-junk"
                 )
library(dubcorms)
```

Source directories and such from data munging RMD
```{r source-chunks, include=FALSE}
### for somet reason i cant get this to work by using dubcorms::source_rmd_chunks(). 
### it works when i enter (go inside) the function but not when run interactively.
temp <- tempfile(fileext=".R")
knitr::purl(params$fn.munging, output = temp)

text <- readr::read_file(temp)
text <- purrr::map(chunk_labels, ~stringr::str_extract(text, glue::glue("(## ----{var})(.|[:space:])*?(?=(## ----)|$)", var = .x))) %>%
    stringr::str_c(collapse = "\n")
readr::write_file(text, temp)
source(temp)
rm(temp, text)
```

Helper functions
```{r helper-funs}
# .trim: function to remove rows where rteno==NA in all relevant objects. 
.trim <- function(x){
  if(is.null(rownames(x))){return(x)} # do nothing if inappropriate for data object
  .rowtrim <- which(rownames(x)=="NA")
  if(length(.rowtrim)==0) return(x)
  x <- x [-.rowtrim,]
  return(x)
}
```


Importing the munged data
```{r import-data}
fns <- list.files(dir.jags, full.names=TRUE)
bbs <- readRDS(fns[str_detect(fns, "bbs.rds")])
ebird <- readRDS(fns[str_detect(fns, "ebird.rds")])
grid <- readRDS(fns[str_detect(fns, "grid.rds")])
args.save <- junk_it(args.save, c("bbs","grid","ebird", ".trim"))
```

# Step 2: Prep BBS Data
## Handle covariates
Calculate the scaled means of stop-level information to serve as route-level covariate values.
```{r prep-bbs-jags-p-arrays, warning=FALSE,message=FALSE}
## scale/mean of stop-level detection covariates
bbs.df <- bbs %>% st_drop_geometry() %>%
  group_by(rteno, year) %>%
  mutate(avgwind = abs(startwind-endwind)/2) %>%
  ungroup() %>% 
  ### scale covariates
  mutate(
    wind.z = (avgwind - mean(avgwind, na.rm=TRUE))/sd(avgwind, na.rm=TRUE),
    noise.z = (noisemean - mean(noisemean, na.rm=TRUE))/sd(noisemean, na.rm=TRUE),
    car.z = (carmean - mean(carmean, na.rm=TRUE))/sd(carmean, na.rm=TRUE)
  ) %>%
  ### weighted counts by prop route in cell and cell area
  mutate(C.weighted.area = as.numeric(C*proprouteincell/area)) %>% # weighted C per grid area (# per m^2)
  as.data.frame()
```

Create arrays describing the covariates influencing detection probabilities.
```{r prep-bbs-jags-p-covars}
### make route-level observation covariate arrays (dims: rteno by year)
p.cars <-  acast(bbs.df %>% distinct(rteno, year, car.z), rteno~year, value.var = "car.z")
p.noise <-  acast(bbs.df %>% distinct(rteno, year, noise.z), rteno~year, value.var = "noise.z")
p.obsfyrbbs <-  acast(bbs.df %>% distinct(rteno, year, obsfirstyearbbs), rteno~year, value.var = "obsfirstyearbbs")
p.obsfyrrteno <-  acast(bbs.df %>% distinct(rteno, year, obsfirstyearroute), rteno~year, value.var = "obsfirstyearroute")
p.wind <-  acast(bbs.df %>% distinct(rteno, year, wind.z), rteno~year, value.var = "wind.z")
## arrays for trend effects
doy.bbs <-  acast(bbs.df %>% distinct(rteno, year, yday), rteno~year, value.var = "yday")
```

Create arrays of BBS count data/
```{r prep-bbs-jags-count-arrays}
## before creating observations at the route level, ensure the empty data (i.e. RTENO is NA) are gone
bbs.df.sampled <- bbs.df %>% filter(!is.na(rteno))
### C.route: C at route level; matrix <rteno by year>
C.route <- reshape2::acast(bbs.df.sampled %>% distinct(rteno, year, C), rteno~year, value.var="C") 
```

Create array for area offsets and weights on the count data. 
```{r prep-bbs-jags-area-offsets}
### w.prop: matrix containing weights for count data (dims: rteno by grid cell)
### we don't slice by year because we don't have route locations within grids across time.
bbs.temp <-  bbs.df %>% units::drop_units() %>% distinct(rteno, gridcellid, proprouteincell)
### complete missing grid cells and years.
w.prop <-
  acast(bbs.temp,
    rteno ~ gridcellid,
    value.var = "proprouteincell"
  ) %>%    # % of rteno in a cell
  tidyr::replace_na(0)
### drop the last row in w.prop if RTENO == NA
if(any(which(rownames(w.prop)=="NA"))) w.prop <- w.prop[-which(rownames(w.prop)=="NA"),]

## w.area: an area offset; vector containing area (m^2) for each grid id (dims: grid cell by 1)
w.area <- scale(as.vector(
  reshape2::acast(
    bbs.df %>% distinct(gridcellid, area),
    gridcellid ~ .,
    value.var = "area"
  )
)) %>% # area (units in original df) of grid cell.
as.vector() # yes, we have to do twice and idk why whatever
```


Create indicators for use in JAGS loops
```{r prep-bbs-jags-loop-inds}
R.bbs = dim(C.route)[1] # <route> number of unique BBS routes with data
T.bbs = dim(C.route)[2] # <time> number of years of BBS data
```

```{r c.grid-arrays}
### C: count at route level; array <rteno by year by grid cell id>
C.grid.temp  <- reshape2::acast(bbs.df %>% distinct(rteno, year, gridcellid, C), rteno~year~gridcellid, value.var="C")
### drop all rows where rowname==NA (yes this is a gross workaround and could probbably be improved)
n.grid <- bbs.df$gridcellid %>% unique() %>% length()
x=dim(C.grid.temp)[1]
ind = rownames(C.grid.temp)[x]
if(is.na(ind) | ind == "NA") C.grid <- C.grid.temp[-x,,]
rm(C.grid.temp, temp, x)
```

Create an array comprising the grid and route-level counts WEIGHTED by proportion of a route in a given grid cell.
```{r c.weighted.arrays}
## make an array comprising the counts per route WEIGHTED by the proportion of the route inside a given grid cell
### total count per route and grid in a year
C.grid.weighted <- array(data=NA, dim=dim(C.grid))
### total BBS count inside a grid cell across *all routes in that grid* in a year
C.grid.weighted.sum <- array(data=NA, dim=c(dim(C.grid)[3], T.bbs)) # 
for(t in 1:ncol(C.grid)){ # time/year
for(g in 1:dim(C.grid)[3]){ # across grids
  for(r in 1:nrow(C.grid)){ # across unique routes
      raw.count <- C.grid[r,t,g]
      prop <- w.prop[r,g] # w.prop==route by grid
      C.grid.weighted[r,t,g] <- prop*raw.count # dims route by time by grid
    } # end route (r) loop
      gridsum = sum(C.grid.weighted[,t,g], na.rm=TRUE)
      C.grid.weighted.sum[g,t] <- gridsum # dims grid by time
  }
}
## matrix comprising total obs WEIGHTED counts
C.route.weighted.sum <- array(data=NA, dim=c(R, T.bbs))
for(r in 1:R){
for(t in 1:T.bbs){
    routesum <- sum(C.grid[r,t,]*w.prop[r,], na.rm=TRUE)
    C.route.weighted.sum[r,t] <- routesum
}
}
```


Specify what to throw into the JAGS list
```{r specify-vars-bbs-jdat}
names.bbs <-
  c(
    "R.bbs", # number of unique routes across entire dataset
    "T.bbs", # will likely always equal T, but just in case
    "C.route",
    "C.grid", ## total count per grid
    "C.grid.weighted", ## C per grid per route weighted by w.prop
    "C.grid.weighted.sum", ## total C per grid weighted by w.prop
    "C.route.weighted.sum", ## total weighted C per route by year
    "w.area",
    "w.prop",
    "p.obsfyrbbs",
    "p.obsfyrrteno",
    "p.cars",
    "p.noise",
    "p.wind",
    "doy.bbs"
  )
```
Finally, wrap it all up into a nice little JAGS list.
```{r make-bbs-jdat}
jdat.bbs <- list()
for(i in seq_along(names.bbs)){
  jdat.bbs[[i]] <- eval(parse(text=paste(names.bbs[i])))
  names(jdat.bbs)[[i]] <- names.bbs[i] # doing this inside loop to prevent issues where data DNE
  jdat.bbs[[i]] <- .trim(jdat.bbs[[i]])
}

```

## BBS data structures/dims
Get the dimensions of the BBS data objects in jdat
```{r data-structure-bbs, eval=FALSE}
### will turn this into a function probably so we can grab dims of all our data.
for(i in seq_along(jdat.bbs)){
  if(i == 1 ){
    bbs.structure = data.frame(matrix(nrow=max(seq_along(jdat.bbs)), ncol=5)) 
    colnames(bbs.structure) = c("class", "length", "nrow", "ncol", "nslice") 
              }
  dat   <-  jdat.bbs[[i]]
  class <-  class(dat)[1] # for multiple classifications will just take the first
  nrow   = dim(dat)[1] #num cols
  ncol   = dim(dat)[2] #num rows
  nslice = dim(dat)[3] #num slices
  # if all those are NA, then its a single value.
  if(all(is.na(c(nrow, ncol, nslice)))){length=length(dat)}else{length=NA}
  if(is.null(nrow))nrow=NA    
  if(is.null(ncol))ncol=NA    
  if(is.null(nslice))nslice=NA    
  
  
  bbs.structure[i,1] <- class
  bbs.structure[i,2] <- length
  bbs.structure[i,3] <- nrow
  bbs.structure[i,4] <- ncol
  bbs.structure[i,5] <- nslice
  rownames(bbs.structure)[i] <-  names(jdat.bbs)[i] 
}
# for reference
# View(bbs.structure)
# kableExtra::kable(bbs.structure) %>%
#   kableExtra::kable_minimal()
args.save <- junk_it(args.save, c("jdat.bbs", "bbs.structure"))
```



## Step 3: Prep eBird Data
Calculate scaled means of event-level information to serve as covariate values.
```{r prep-ebird-jags-p-arrays, warning=FALSE,message=FALSE}
ebird.df <- ebird %>%
  st_drop_geometry() %>%
  as.data.frame() %>%
  distinct() %>% ## not sur why there are d to check this upstream later!!!
  filter(number_observers < 10) %>% ### some strange number of observers exist... going to limit to 10 observers arbitrarily
  ### scale covariates
  mutate(
    duration_minutes.z = (duration_minutes - mean(duration_minutes, na.rm=TRUE))/sd(duration_minutes, na.rm=TRUE),
    effort_area.z = (effort_area_ha - mean(effort_area_ha, na.rm=TRUE))/sd(effort_area_ha, na.rm=TRUE),
    effort_distance_km.z = (effort_distance_km - mean(effort_distance_km, na.rm=TRUE))/sd(effort_distance_km, na.rm=TRUE),
    number_observers.z = (number_observers - mean(number_observers, na.rm=TRUE))/sd(number_observers, na.rm=TRUE)
  )

## add the empty grid cells to the ebird data frame
## a join will eat up too much time/comp capacity so we should just impute rows
# full_join(ebird.df, as.data.frame(grid) %>% dplyr::select(-geometry))
missing <- setdiff(ebird.df$gridcellid, grid$gridcellid)
if(length(missing)!=0) "NEED TO ADD FUNCTION HERE TO IMPUTE THE MISSING CELLS"
```

Create some indexing on the eBird data for JAGS
```{r prep-ebird-jags-indexing}
```

Create arrays for eBird count data (dims: checklist by year by grid cell)
```{r prep-ebird-jags-count-arrays}

```

Create array for area offsets and weights on the count data. 
```{r prep-ebird-jags-area-offsets}

```

Create indicators for use in JAGS loops
```{r prep-ebird-jags-loop-inds}

```

Specify what to throw into the JAGS list
```{r specify-vars-ebird-jdat}
```

Finally, wrap it all up into a nice little JAGS list.
```{r make-ebird-jdat}
jdat.ebird <- list(ebird)

args.save <- junk_it(args.save, "jdat.ebird")
```

# Step 3: Prep Grid/Study Area
Create some indicators describing the grid for use in JAGS.
```{r prep-grid-jags}
## create a data frame for indexing off the grid cell
grid.df <- grid %>%
  arrange(gridcellid) %>%
  st_drop_geometry()

### create an index for the grid cells with count data
gridcellswbbs <- bbs %>% st_drop_geometry() %>% 
  filter(!is.na(C)) %>% distinct(gridcellid) %>% pull(gridcellid) %>% sort()
gridcellswebird <- ebird %>% st_drop_geometry() %>% 
  filter(!is.na(C)) %>% distinct(gridcellid) %>% pull(gridcellid) %>% sort()

gridcellswdata <- unique(c(gridcellswbbs, gridcellswebird))

## grid cell centroid coordinates
XY <- grid.df %>% # centroid coordinates of the grid cells
  select(cell.lon.centroid, cell.lat.centroid) %>% as.matrix()
```

```{r make-integrated-indexes}
years <- min(c(ebird$year, bbs$year), na.rm=TRUE):max(c(ebird$year, bbs$year), na.rm=TRUE)
T    <- length(years) # avoid using "T" becuse T==TRUE and hard to redefine
G     <- length(unique(grid$gridcellid))

## test to see if ebird and bbs have same num years of data. this test needs major improvement.
if(!length(unique(ebird$year, na.rm=TRUE)!=T))"years of data do not match bbs"
if(!length(unique(bbs$year, na.rm=TRUE)!=T))"years of data do not match ebird"
```
Wrap up relevant data into a nice little JAGS list
```{r make-grid-jdat}
### create a list of elements relevant to the study area/grid cells
jdat.grid <- list(
  area = grid.df$area,
  period = years, # min and max years of data in integrated data
  T = T, # length of total time period (with or wihtout data)
  coords.gridcells = XY,
  G = nrow(XY), # integer, number of cells in study area (with or without data)
  # n.gridcellswdata = length(gridcellswdata), # number of grid cells with any count data (ebird or bbs)
  # id.gridcellswdata = sort(gridcellswdata),  # vector of grid cell ids with any count data
  # n.gridcellswbbs = length(gridcellswbbs), # number of grid cells with any count data (ebird or bbs)
  # id.gridcellswbbs = sort(gridcellswbbs),  # vector of grid cell ids with any count data
  # n.gridcellswebird = length(gridcellswebird), # number of grid cells with any count data (ebird or bbs)
  # id.gridcellswebird = sort(gridcellswebird),  # vector of grid cell ids with any count data
  id.gridcells = sort(grid.df$gridcellid) # identifier for grid cells
  )
args.save <- junk_it(args.save, "jdat.grid")
```

# Step 4: Join Data and Export
```{r write-jdat}
jdat <- list(jdat.bbs, jdat.ebird, jdat.grid)
names(jdat) <- c("bbs", "ebird","grid")
saveRDS(jdat, file=paste0(dir.jags, "jdat.rds"))
```

